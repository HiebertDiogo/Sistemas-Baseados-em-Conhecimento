{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "436aedf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "##### Notebook Explainability\n",
    "##### Baseado em:\n",
    "##  Dataset: https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset\n",
    "##\n",
    "##############################################################################################################\n",
    "## Objetivos:\n",
    "##   Demonstrar os principais metodos de explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0bbec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost\n",
    "#!pip install dice-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fa6a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"c:\\Users\\Masmok\\miniconda3\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"c:\\Users\\Masmok\\miniconda3\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\Masmok\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\Masmok\\AppData\\Roaming\\Python\\Python310\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\Masmok\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\Masmok\\AppData\\Roaming\\Python\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\Masmok\\miniconda3\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\Masmok\\miniconda3\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\Masmok\\miniconda3\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\Masmok\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\Masmok\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\Masmok\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\Masmok\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\Masmok\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\Masmok\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\Masmok\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\Masmok\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\Masmok\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Masmok\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\Masmok\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\Masmok\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Masmok\\AppData\\Local\\Temp\\ipykernel_17568\\868752044.py\", line 3, in <module>\n",
      "    from sklearn.model_selection import train_test_split\n",
      "  File \"C:\\Users\\Masmok\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\__init__.py\", line 87, in <module>\n",
      "    from .base import clone\n",
      "  File \"C:\\Users\\Masmok\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py\", line 19, in <module>\n",
      "    from .utils import _IS_32BIT\n",
      "  File \"C:\\Users\\Masmok\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\__init__.py\", line 16, in <module>\n",
      "    from scipy.sparse import issparse\n",
      "  File \"C:\\Users\\Masmok\\AppData\\Roaming\\Python\\Python310\\site-packages\\scipy\\sparse\\__init__.py\", line 267, in <module>\n",
      "    from ._csr import *\n",
      "  File \"C:\\Users\\Masmok\\AppData\\Roaming\\Python\\Python310\\site-packages\\scipy\\sparse\\_csr.py\", line 10, in <module>\n",
      "    from ._sparsetools import (csr_tocsc, csr_tobsr, csr_count_blocks,\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# import imblearn\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomOverSampler\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\__init__.py:87\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     84\u001b[0m         __check_build,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     85\u001b[0m         _distributor_init,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     86\u001b[0m     )\n\u001b[1;32m---> 87\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[0;32m     90\u001b[0m     __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     91\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     92\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    134\u001b[0m     ]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _IS_32BIT\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HTMLDocumentationLinkMixin, estimator_html_repr\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester, _routing_enabled\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\__init__.py:16\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compress, islice\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m issparse\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataConversionWarning\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\scipy\\sparse\\__init__.py:267\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_warnings\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m--> 267\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_csr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_csc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\scipy\\sparse\\_csr.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m spmatrix\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sparsetools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (csr_tocsc, csr_tobsr, csr_count_blocks,\n\u001b[0;32m     11\u001b[0m                            get_csr_submatrix)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sputils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m upcast, get_index_dtype\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compressed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _cs_matrix\n",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import imblearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from interpret.blackbox import LimeTabular\n",
    "from interpret import show\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import shap\n",
    "# import dice_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a6916a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "\n",
    "    def load_dataset(self, path=\"C:/Users/dealbuqc/Desktop/ontomqol/Datasets/stroke/healthcare-dataset-stroke-data.csv\"):\n",
    "        self.data = pd.read_csv(path)\n",
    "\n",
    "    def preprocess_data(self, key=0):\n",
    "        # One-hot encode para todas as colunas categoricas\n",
    "        categorical_cols = [\"gender\",\n",
    "                            \"ever_married\",\n",
    "                            \"work_type\",\n",
    "                            \"Residence_type\",\n",
    "                            \"smoking_status\"]\n",
    "        encoded = pd.get_dummies(self.data[categorical_cols], \n",
    "                                prefix=categorical_cols, dtype=float)\n",
    "\n",
    "        # Atualiza dataset com novas colunas\n",
    "        self.data = pd.concat([encoded, self.data], axis=1)\n",
    "        self.data.drop(categorical_cols, axis=1, inplace=True)\n",
    "\n",
    "        # Incluir valores que faltam na coluna BMI\n",
    "        self.data.bmi = self.data.bmi.fillna(0)\n",
    "        #self.data.drop(self.data[self.data['bmi'] < 10].index, inplace=True)\n",
    "        \n",
    "        # Drop id - caracteristica nao eh relevante\n",
    "        self.data.drop([\"id\"], axis=1, inplace=True)\n",
    "\n",
    "        \n",
    "\n",
    "    def get_data_split(self):\n",
    "        X = self.data.iloc[:,:-1]\n",
    "        y = self.data.iloc[:,-1]\n",
    "        return train_test_split(X, y, test_size=0.20, random_state=2021)\n",
    "    \n",
    "    def oversample(self, X_train, y_train):\n",
    "        oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "        # Converte para numpy e oversample\n",
    "        x_np = X_train.to_numpy()\n",
    "        y_np = y_train.to_numpy()\n",
    "        x_np, y_np = oversample.fit_resample(x_np, y_np)\n",
    "        # Convert de volta para pandas\n",
    "        x_over = pd.DataFrame(x_np, columns=X_train.columns)\n",
    "        y_over = pd.Series(y_np, name=y_train.name)\n",
    "        return x_over, y_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37a4303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7778, 21)\n",
      "(1022, 21)\n"
     ]
    }
   ],
   "source": [
    "# Carregar dados\n",
    "data_loader = DataLoader()\n",
    "data_loader.load_dataset()\n",
    "data_loader.preprocess_data()\n",
    "\n",
    "# Separar em treinamento e avaliacao, fazendo o oversampling\n",
    "X_train, X_test, y_train, y_test = data_loader.get_data_split()\n",
    "X_train, y_train = data_loader.oversample(X_train, y_train)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f25fd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score 0.5293487041273149\n",
      "Accuracy 0.9403131115459883\n"
     ]
    }
   ],
   "source": [
    "# %% Treinar o modelo blackbox (pode ser qualquer um aqui)\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print(f\"F1 Score {f1_score(y_test, y_pred, average='macro')}\")\n",
    "print(f\"Accuracy {accuracy_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65df0d6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/1759615103184/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/1759615103184/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aplicar LIME\n",
    "\n",
    "# Classificacao: predict_proba. Regressao: predict)\n",
    "lime = LimeTabular(rf, \n",
    "                   X_train) # precisa do dataset para gerar as perturbacoes\n",
    "\n",
    "# Retornar explanation\n",
    "lime_local = lime.explain_local(X_test[-20:], \n",
    "                                y_test[-20:], \n",
    "                                name='LIME')\n",
    "show(lime_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b41998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar SHAP\n",
    "\n",
    "import xgboost\n",
    "\n",
    "model = xgboost.XGBClassifier(n_estimators=20)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "explainer = shap.Explainer(model)\n",
    "shap_values = explainer(X_train)\n",
    "shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3d59f1-7f7d-4f85-b82e-c5242b02e24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5307b9ce-7f97-4f98-b724-42eae0591e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.lmplot(x=\"age\", y=\"bmi\", data=X_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6489a440-1606-4a1d-89ea-19ae343e760f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train))\n",
    "df_test = X_train.drop(X_train[X_train['bmi'] < 10].index) # abaixo de 18 ja eh desnutrido/modelo. Impossivel abaixo de 10\n",
    "print(len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e578d452-43fe-4b12-b47d-150c0d3e3ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"age\", y=\"bmi\", data=df_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273b7ca7-d92b-4361-83e6-6aa56454f4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5902f0ef-58f2-4429-8dd0-d2064e2b5546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "\n",
    "model = xgboost.XGBClassifier(n_estimators=20)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "explainer = shap.Explainer(model)\n",
    "shap_values = explainer(df_test)\n",
    "shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cef0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar DiCE  (Diverse Counterfactual Explanations)\n",
    "\n",
    "# Dataset\n",
    "data_dice = dice_ml.Data(dataframe=data_loader.data, \n",
    "                         # Indicar quem sao as caracteristicas continuas (para perturbacao)\n",
    "                         continuous_features=['age', \n",
    "                                              'avg_glucose_level',\n",
    "                                              'bmi'], \n",
    "                         outcome_name='stroke')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ac2d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo\n",
    "rf_dice = dice_ml.Model(model=rf, \n",
    "                        backend=\"sklearn\") # tf, torch, ...\n",
    "explainer = dice_ml.Dice(data_dice, \n",
    "                         rf_dice, \n",
    "                         # Random sampling, genetic algorithm, kd-tree,... (Ver github.com/)\n",
    "                         # Ver github.com/interpretml/DICE para outras opcoes incluindo para DL\n",
    "                         method=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83164a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Criar explanations\n",
    "input_datapoint = X_test[0:1]\n",
    "cf = explainer.generate_counterfactuals(input_datapoint, \n",
    "                                  total_CFs=3, \n",
    "                                  desired_class=\"opposite\")\n",
    "\n",
    "# Visualizar\n",
    "cf.visualize_as_dataframe(show_only_changes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75650a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Criar contrafatos condicionais\n",
    "features_to_vary=['avg_glucose_level',\n",
    "                  'bmi',\n",
    "                  'smoking_status_smokes']\n",
    "permitted_range={'avg_glucose_level':[80,250],\n",
    "                'bmi':[18, 35]}\n",
    "\n",
    "cf = explainer.generate_counterfactuals(input_datapoint, \n",
    "                                  total_CFs=3, \n",
    "                                  desired_class=\"opposite\",\n",
    "                                  permitted_range=permitted_range,\n",
    "                                  features_to_vary=features_to_vary)\n",
    "# Visualizacao\n",
    "cf.visualize_as_dataframe(show_only_changes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afb9fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "### Codigo abaixo nao vai ser exigido\n",
    "#######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df5403a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from innvestigate import create_analyzer\n",
    "\n",
    "# Carregar os pesos do modelo pre-treinado VGG16\n",
    "model = VGG16(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86081430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar um exemplo de imagem\n",
    "img_path = 'C:/Users/dealbuqc/Desktop/ontomqol/Datasets/brain-mri/Testing/glioma_tumor/image(1).jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4602fe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a831de1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificacao da imagem (classificao)\n",
    "preds = model.predict(x)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77c6d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ESSE CODIGO VAI GERAR UM ERRO. TENTE ENTENDER O MOTIVO!\n",
    "\n",
    "# Create an LRP analyzer\n",
    "#analyzer = create_analyzer(\"lrp.z\", model)\n",
    "analyzer = create_analyzer(\"gradient\", model)\n",
    "\n",
    "# Aplicar o LRP a image\n",
    "analysis = analyzer.analyze(x)\n",
    "\n",
    "# Plotar o heatmap\n",
    "plt.imshow(analysis.squeeze(), cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# Para uma implementacao correta (em pytorch), ver link abaixo:\n",
    "# https://www.kaggle.com/code/gustavkeppler/layer-wise-relevance-propagation-lrp-on-vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c6eab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver um demo em: \n",
    "### https://lrpserver.hhi.fraunhofer.de/image-classification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
